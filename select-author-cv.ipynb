{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code was created for submission to Data Science for Good: CareerVillage.org\n",
    "Here are the codes for the following two processes:\n",
    "\n",
    "1, The first process is data reading, copying, tokenizing, etc. The execution time is about 10 minutes on the PC, and is executed when updating data.\n",
    " Processing items and flows are as followings.\n",
    "- Read csv data\n",
    "- Copy \"answers\", \"questions\", \"professionals\" for data processing and addition\n",
    "- Add 'score' column from answer_scores to answers_copy\n",
    "- Add 'score' column from question_scores to questions_copy\n",
    "- Calculate response days from question to the answer, and add it to answers_copy\n",
    "- Tokenize from questions_title and questions_body to questions_words\n",
    "- Get tags from questions_body to questions_body_tags\n",
    "- Merge professionals_industry and professionals_headline, and tokenize them to 'ind_head'.\n",
    "- Join ind_head to ind_head_sp with space, for high-speed search\n",
    "- Convert professionals_date_joined to professionals_date_joined_dt with Datetime format \n",
    "\n",
    "2, The second process actually enters a question and selects authors for the answer. \n",
    "  Processing items and flows are as follows, and it takes about 6 seconds by PC(i7/8GB)\n",
    "- Two input methods are prepared.\n",
    "        (1)The first method is to input title and body directly by str.\n",
    "        (2)The second is a method of specifying the index of Framedata of \"questions\" by integer.\n",
    "- The hyper parameters are below.\n",
    "        'number_of_authors': Number of authors to select. default[10]\n",
    "        'sample_num': Number of questions to compare similarity, larger number takes processing time. default[10]\n",
    "        'tag_coef': Priority coefficient of tag for body words in calculating questions similarity. default[2]\n",
    "        'expiration_date': Similar questions prioritize newer ones within 'expiration_date'.  default[1000]\n",
    "        'reseponse_time_limit': Similar answer prioritize faster response to the answer within 'reseponse_time_limit'.  default[30] \n",
    "        'thank_coef':  Priority coefficient of the number of \"thank\" included in the comment of the answer. default[1]\n",
    "        'rand_coef': Random coefficient of 0. to 1., 0.[default]: select from rank high, 1.: 100% random.  default[0] 'rand_coef' can add fluctuation to the selection  \t\t\t\t\t \n",
    "- Calucurate questions_copy['questions_similarity'] to input question by Jaccard similarity.\n",
    "        questions_similarity = (jaccard_index(word)+jaccard_index(tag)*tag_coef)*(log(score+1)+1)*(1-delta_day/expiration_date)\n",
    "- Choose 'questions_selected' of quantity of 'sample_num'\n",
    "- Select answers of the 'questions_selected'\n",
    "- Count 'thank' from the comments of each answer.\n",
    "- Listed aurhors of the selected answers and calculate the author_priority from score, Response_day, questions_similarity and number of \"thank\".      \n",
    "        author_selected['author_priority'] = (1 + author_selected['thank_mean'] * thank_coef) * author_selected['similarity_mean'] * author_selected['answer_count'] * (1 - author_selected['respose_day_mean'] / reseponse_time_limit) * author_selected['score_mean']\n",
    "- Collect words from the selected authors and aggregate the author_priority to each words.\n",
    "- Calculate professionals_priority for all of professionals by words' priority.\n",
    "- Set higher 'author_priority' for 'author_selected'\n",
    "- Sort professionals by the priority and select recommendation of professionals due to 'rand_coef'\n",
    "        select.index = int((1-random.random()**rand_coef)*professionals_sorted.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime as dt\n",
    "import sys, time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function of delta_days = date1 - date2\n",
    "def delta_days(date1, date2):\n",
    "    d1=dt.datetime.strptime(date1[:19], '%Y-%m-%d %H:%M:%S')\n",
    "    d2=dt.datetime.strptime(date2[:19], '%Y-%m-%d %H:%M:%S')\n",
    "    return (d1-d2).days+(d1-d2).seconds/(3600*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function of days_to_now\n",
    "def days_to_now(date):\n",
    "    d1=dt.datetime.now()\n",
    "    d2=dt.datetime.strptime(date[:19], '%Y-%m-%d %H:%M:%S')\n",
    "    return (d1-d2).days+(d1-d2).seconds/(3600*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing function\n",
    "stopWords = set(stopwords.words('english'))\n",
    "stopWords |= set([\"n't\",\"'m\",\"'re\",\"'ve\",\"'s\",\".\", \"|\", 'ï¼‹', \"^\", \"=\"])\n",
    "def get_word_list(text):\n",
    "    text_tokenized = [wt[0].lower() for wt in nltk.pos_tag(nltk.word_tokenize(text)) \\\n",
    "                      if ('NN'  in wt[1]) or ('JJ'  in wt[1]) or ('RB'  in wt[1]) or ('VB'  in wt[1])]\n",
    "    return [w for w in text_tokenized if w not in stopWords if w!='+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function of getting tag list from text\n",
    "def get_tag_list(text):\n",
    "    tag_name = []\n",
    "    wl=word_tokenize(text)\n",
    "    for i,w in enumerate(wl):\n",
    "        if ('#' in w) and (i != len(wl)-1) and (len(w)>0):\n",
    "            if len(wl[i+1])>1:\n",
    "                tag_name.append(wl[i+1].lower())\n",
    "    return tag_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jaccard similarity\n",
    "def get_jac_sim(content1,content2):\n",
    "    a=set(content1)\n",
    "    b=set(content2)\n",
    "    if len(a.union(b))==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(a.intersection(b))/len(a.union(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and data preprocessing\n",
    "def processing_data():\n",
    "    \n",
    "    #Update files\n",
    "    print('---  1/10',\"\\r\", end=\"\")\n",
    "    answer_scores = pd.read_csv('../input/answer_scores.csv')\n",
    "    answers = pd.read_csv('../input/answers.csv')\n",
    "    comments = pd.read_csv('../input/comments.csv')\n",
    "    professionals = pd.read_csv('../input/professionals.csv')\n",
    "    question_scores = pd.read_csv('../input/question_scores.csv')\n",
    "    questions = pd.read_csv('../input/questions.csv')\n",
    "\n",
    "    #Copy three files for data processing\n",
    "    print('---  2/10',\"\\r\", end=\"\")\n",
    "    answers_copy=copy.copy(answers)\n",
    "    questions_copy=copy.copy(questions)\n",
    "    professionals_copy=copy.copy(professionals)\n",
    "\n",
    "    #Add 'score' column from answer_scores to answers_copy\n",
    "    print(\"---  3/10\",\"\\r\", end=\"\")\n",
    "    answers_copy['score']=0\n",
    "    answers_arr=answers_copy.values\n",
    "    answer_s_arr=answer_scores.values\n",
    "    for i in range(len(answers_arr)):\n",
    "        search_arr=np.any(answer_s_arr==answers_arr[i,0], axis=1)\n",
    "        if any(search_arr)==True:\n",
    "            answers_arr[i,5]=answer_s_arr[search_arr,1][0]\n",
    "    answers_copy=pd.DataFrame(answers_arr, index=answers_copy.index, columns=answers_copy.columns)\n",
    "\n",
    "    #Add 'score' column from question_scores to questions_copy\n",
    "    print(\"---  4/10\",\"\\r\", end=\"\")\n",
    "    questions_copy['score']=0\n",
    "    questions_arr=questions_copy.values\n",
    "    question_s_arr=question_scores.values\n",
    "    for i in range(len(questions_arr)):\n",
    "        searchq_arr=np.any(question_s_arr==questions_arr[i,0], axis=1)\n",
    "        if any(searchq_arr)==True:\n",
    "            questions_arr[i,5]=question_s_arr[searchq_arr,1][0]\n",
    "    questions_copy=pd.DataFrame(questions_arr, index=questions_copy.index, columns=questions_copy.columns)\n",
    "\n",
    "    #Calculate response days from question to the answer, and add it to answers_copy\n",
    "    print(\"---  5/10\",\"\\r\", end=\"\")\n",
    "    for i in answers.index:\n",
    "        answers_copy.loc[i,'Response_day']=delta_days(answers_copy.loc[i,'answers_date_added'],\n",
    "            questions_copy[questions_copy['questions_id']==answers_copy.loc[i,'answers_question_id']].iloc[0]['questions_date_added'])\n",
    "\n",
    "    #Tokenize from questions_title and questions_body to questions_words\n",
    "    print(\"---  6/10\",\"\\r\", end=\"\")\n",
    "    questions_copy['questions_words']=[get_word_list(x) for x in (questions_copy['questions_body'] +\n",
    "                                                                  ' ' + questions_copy['questions_title'])]\n",
    "\n",
    "    #Get tags from questions_body to questions_body_tags\n",
    "    print(\"---  7/10\",\"\\r\", end=\"\")\n",
    "    questions_copy['questions_body_tags']=[get_tag_list(x) for x in questions_copy['questions_body']]\n",
    "\n",
    "    #Merge (professionals_location,) professionals_industry and professionals_headline to ind_head\n",
    "    print(\"---  8/10\",\"\\r\", end=\"\")\n",
    "    professionals_copy = professionals_copy.fillna('')\n",
    "    professionals_copy['ind_head'] = ''\n",
    "    for x in professionals_copy.index:\n",
    "        professionals_copy.at[x,'ind_head'] = set(get_word_list(professionals_copy.loc[x,'professionals_industry'])) | \\\n",
    "                set(get_word_list(professionals_copy.loc[x,'professionals_headline'])) \n",
    "\n",
    "    # Join ind_head to ind_head_sp with space for high-speed search \n",
    "    print(\"---  9/10\",\"\\r\", end=\"\")\n",
    "    professionals_copy['ind_head_sp']=[\" \".join(x) for x in professionals_copy['ind_head']]\n",
    "\n",
    "    # Convert professionals_date_joined to professionals_date_joined_dt with Datetime format \n",
    "    print(\"--- 10/10\",\"\\r\", end=\"\")\n",
    "    professionals_copy['professionals_date_joined_dt']=[dt.datetime.strptime(professionals_copy.loc[x,'professionals_date_joined'][:19],\n",
    "                                                                        '%Y-%m-%d %H:%M:%S') for x in professionals_copy.index]\n",
    "    print(\"Finished \",\"\\r\")\n",
    "    return answers_copy, questions_copy, professionals_copy, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  \r\n",
      "CPU times: user 7min 55s, sys: 1.89 s, total: 7min 57s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%time answers_copy, questions_copy, professionals_copy, comments = processing_data()\n",
    "# it takes about 12minuts by PC(i7/8GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_author(input_question, number_of_authors, sample_num, tag_coef, expiration_date, \n",
    "                  reseponse_time_limit, thank_coef, rand_coef):\n",
    "    \n",
    "    # calucurate questions_similarity in the case of type(input_question)==int: existing question on the data\n",
    "    print('---  1/6',\"\\r\", end=\"\")\n",
    "    if type(input_question)==int:\n",
    "        if input_question in questions_copy['questions_words']:\n",
    "            questions_copy['questions_similarity'] = [(get_jac_sim(questions_copy['questions_words'][input_question],\n",
    "                            questions_copy['questions_words'][i]) + get_jac_sim(questions_copy['questions_body_tags'][input_question],\n",
    "                            questions_copy['questions_body_tags'][i])*tag_coef)* (math.log10(questions_copy['score'][i]+1)+1)\n",
    "                            * (1 - delta_days(questions_copy['questions_date_added'][input_question],\n",
    "                            questions_copy['questions_date_added'][i])/expiration_date) for i in questions_copy.index]\n",
    "            if questions_copy.loc[input_question,'questions_id'] in answers_copy['answers_question_id'].values:\n",
    "                old_item=1\n",
    "            else:\n",
    "                old_item=0\n",
    "        else:\n",
    "            print('Err: No applicable questions.index')\n",
    "            sys.exit()\n",
    "\n",
    "    # calucurate questions_similarity in the case of type(input_question)==str: new question\n",
    "    elif type(input_question)==str:\n",
    "        word_list = get_word_list(input_question)\n",
    "        tag_list = get_tag_list(input_question)\n",
    "        questions_copy['questions_similarity'] = [(get_jac_sim(word_list, questions_copy['questions_words'][i]) \\\n",
    "                            + get_jac_sim(tag_list, questions_copy['questions_body_tags'][i])*tag_coef) \\\n",
    "                            * (math.log10(questions_copy['score'][i]+1)+1) * (1 - days_to_now(questions_copy['questions_date_added'][i]) \\\n",
    "                            /expiration_date) for i in questions_copy.index]\n",
    "        old_item=0\n",
    "    else:\n",
    "        print('Err: type error')\n",
    "        sys.exit()\n",
    "        \n",
    "    #select questions similar to input\n",
    "    print('---  2/6',\"\\r\", end=\"\")\n",
    "    questions_selected = questions_copy.sort_values('questions_similarity', ascending=False).iloc[old_item:sample_num+old_item,:]\n",
    "    \n",
    "    #select answers of the selected questions\n",
    "    print('---  3/6',\"\\r\", end=\"\")\n",
    "    answers_selected=pd.DataFrame()\n",
    "    for i in questions_selected.index:        \n",
    "        for j in answers_copy[answers_copy['answers_question_id']==questions_selected['questions_id'].loc[i]].index:\n",
    "            answers_selected= answers_selected.append(answers_copy.loc[j,['answers_id','answers_question_id',\n",
    "                                                                     'answers_author_id', 'answers_date_added','Response_day','score']])\n",
    "            answers_selected.loc[j,'questions_similarity']= questions_selected.loc[i,'questions_similarity']\n",
    "            #Count 'thank' from the comments of each answer. \n",
    "            answers_selected.loc[j,'thank']=int(any(comments[(comments['comments_parent_content_id']==\n",
    "                                                              answers_selected.loc[j, 'answers_id'])]['comments_body'].str.contains('Thank|thank|thk|thnk')))\n",
    "    if len(answers_selected)==0:\n",
    "        print(\"Err: No similar answers, use larger 'sample_num'\")\n",
    "        sys.exit()            \n",
    "    #Listed aurhors of the selected answers and calculate the author_priority from score, Response_day, questions_similarity and thank\n",
    "    print('---  4/6',\"\\r\", end=\"\")\n",
    "    author_selected = answers_selected.groupby('answers_author_id').agg({'answers_id':'count', 'score':'mean', \n",
    "                                                                         'Response_day':'mean', 'questions_similarity': 'mean', 'thank': 'mean'})\n",
    "    author_selected.columns=['answer_count', 'score_mean', 'respose_day_mean', 'similarity_mean', 'thank_mean']\n",
    "    author_selected['score_mean'] = [math.log10(author_selected.loc[x,'score_mean']+1)+1 for x in author_selected.index]\n",
    "    author_selected['author_priority'] = (1+author_selected['thank_mean']*thank_coef)*author_selected['similarity_mean']\\\n",
    "                * author_selected['answer_count']*(1-author_selected['respose_day_mean']/reseponse_time_limit)\\\n",
    "                * author_selected['score_mean']\n",
    "    author_selected=author_selected[author_selected['author_priority']>0]\n",
    "    author_selected['ind_head']=''\n",
    "    for x in author_selected.index:\n",
    "        if any(professionals_copy['professionals_id']==x):\n",
    "            author_selected.at[x, 'ind_head']=[professionals_copy[professionals_copy['professionals_id']==x]['ind_head'].values[0]]\n",
    "\n",
    "    #Collect words from the selected authors and aggregate the author_priority.\n",
    "    print('---  5/6',\"\\r\", end=\"\")\n",
    "    word_set=set()\n",
    "    for i in author_selected.index:\n",
    "        if author_selected.loc[i, 'ind_head'] != '':\n",
    "            word_set|=author_selected.loc[i, 'ind_head'][0]\n",
    "\n",
    "    word_dict = dict(zip(word_set,np.zeros(len(word_set))))\n",
    "    for i in author_selected.index:\n",
    "         if author_selected.loc[i, 'ind_head'] != '':\n",
    "                for j in author_selected.loc[i, 'ind_head'][0]:\n",
    "                    word_dict[j] = word_dict[j]+author_selected.loc[i, 'author_priority']\n",
    "\n",
    "    word_dict = {k: v for k, v in word_dict.items() if v != 0.0}\n",
    "\n",
    "    #Calculate professionals_priority by word_dict.\n",
    "    print('---  5/6',\"\\r\", end=\"\")\n",
    "    professionals_copy['professionals_priority']=0.0\n",
    "    for k, v in word_dict.items():\n",
    "        professionals_copy.loc[professionals_copy['ind_head_sp'].str.contains(k),'professionals_priority']+=v\n",
    "    professionals_priority_max=professionals_copy['professionals_priority'].max()\n",
    "    #Set higher 'author_priority' for 'author_selected'\n",
    "    for i in author_selected.index:\n",
    "        professionals_copy.loc[(professionals_copy['professionals_id']==i),'professionals_priority']+= \\\n",
    "                author_selected.loc[i, 'author_priority']+professionals_priority_max\n",
    "    \n",
    "    #Sort professionals by the priority\n",
    "    print('---  6/6',\"\\r\", end=\"\")\n",
    "    random.seed(dt.datetime.now().microsecond)\n",
    "    professionals_sorted = copy.copy(professionals_copy.sort_values(['professionals_priority','professionals_date_joined_dt'],\n",
    "                                                        ascending=[False, False]))\n",
    "    professionals_sorted['rank']=[i+1 for i in range(professionals_sorted.shape[0])]\n",
    "    selected_professionals = pd.DataFrame()    \n",
    "    # and select recommendation of professionals due to 'rand_coef'\n",
    "    if (rand_coef>=0) and (rand_coef<=1):\n",
    "        for i in range(number_of_authors):\n",
    "            ii = int((1-random.random()**(rand_coef))*professionals_sorted.shape[0])\n",
    "            selected_professionals = selected_professionals.append(professionals_sorted.iloc[ii,:])\n",
    "            professionals_sorted=professionals_sorted.drop(index=professionals_sorted.index[ii])\n",
    "        selected_professionals['rank']=selected_professionals['rank'].astype('int64')\n",
    "    else:\n",
    "        print(\"Err: Input 0. to 1. for 'rand_coef'\")\n",
    "        sys.exit()\n",
    "    \n",
    "    print(\"Finished \",\"\\r\")\n",
    "    return selected_professionals.drop(['ind_head', 'ind_head_sp', 'professionals_date_joined_dt','professionals_priority'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "params = {\n",
    "        'number_of_authors': 10,# Number of authors to select\n",
    "        'sample_num': 10, # Number of sample questions to compare similarity, the biggest factor of the processing time.\n",
    "        'tag_coef': 2, # Priority coefficient of Tag in calculating questions similarity\n",
    "        'expiration_date': 1000, # Similar questions prioritize newer ones within 'expiration_date'\n",
    "        'reseponse_time_limit': 30, # Similar answer prioritize faster response to the answer within in 30 days \n",
    "        'thank_coef': 1, # Priority coefficient of the number of \"thank\" included in the comment of the answer\n",
    "        'rand_coef': 0.} # Random coefficient of 0. to 1., 0.[default]: select from high order, 1.: 100% random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two input methods are prepared.\n",
    "The first method is to input title and body directly by str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  \r\n",
      "CPU times: user 4.19 s, sys: 20 ms, total: 4.21 s\n",
      "Wall time: 4.19 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_date_joined</th>\n",
       "      <th>professionals_headline</th>\n",
       "      <th>professionals_id</th>\n",
       "      <th>professionals_industry</th>\n",
       "      <th>professionals_location</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18204</th>\n",
       "      <td>2018-04-10 13:19:06 UTC+0000</td>\n",
       "      <td>Creative Director | Art Director | Designer</td>\n",
       "      <td>16584031624041119309e01c908a2f1f</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2015-12-16 23:48:37 UTC+0000</td>\n",
       "      <td>Principal, Illustrator, Graphic Designer at Ki...</td>\n",
       "      <td>349db306672e425f9481e6c30d84afe5</td>\n",
       "      <td>GRAPHIC_DESIGN, ILLUSTRATION</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>2015-03-09 11:20:00 UTC+0000</td>\n",
       "      <td>Keeping Busy!!! - Illustrator and Designer, al...</td>\n",
       "      <td>e01894b52bfb4eabb8791beaef276fa7</td>\n",
       "      <td>Civil Engineering</td>\n",
       "      <td>Frome, England, United Kingdom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3045</th>\n",
       "      <td>2015-12-15 16:59:08 UTC+0000</td>\n",
       "      <td>Illustrator and Graphic Designer</td>\n",
       "      <td>4bbd6d03e36b445198780896632a01f1</td>\n",
       "      <td>Graphic Design</td>\n",
       "      <td>Missoula, Montana</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>2014-05-15 16:57:38 UTC+0000</td>\n",
       "      <td>Principal Artist at Zynga</td>\n",
       "      <td>bc46e3699d92477ba8c7aa723e54a151</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>2017-05-22 20:45:47 UTC+0000</td>\n",
       "      <td>Making the donuts at Okta</td>\n",
       "      <td>67c1bd0e570e447ba48f25bcdc073297</td>\n",
       "      <td>Graphic Design</td>\n",
       "      <td>Portland, Oregon</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23605</th>\n",
       "      <td>2018-09-25 23:10:33 UTC+0000</td>\n",
       "      <td>Solutions Manager</td>\n",
       "      <td>cdeef38b72d54b65b0f826261d33276b</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13045</th>\n",
       "      <td>2017-09-18 22:44:13 UTC+0000</td>\n",
       "      <td>Princpal Catalog Expert  at SAP Ariba</td>\n",
       "      <td>562bbe2bad304300aa551dceecf5e440</td>\n",
       "      <td>Information Services</td>\n",
       "      <td>Santa Clarita, California</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15436</th>\n",
       "      <td>2018-01-17 20:18:04 UTC+0000</td>\n",
       "      <td></td>\n",
       "      <td>a209eed08b8846adaf95f352b1325815</td>\n",
       "      <td></td>\n",
       "      <td>Hallandale Beach, Florida</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>2016-12-06 11:49:51 UTC+0000</td>\n",
       "      <td>Advertising &amp; Marketing, Graphic Designer, Art...</td>\n",
       "      <td>113c32498e0f4c67929b194a549655db</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Jeddah, Makkah Province, Saudi Arabia</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          professionals_date_joined ...  rank\n",
       "18204  2018-04-10 13:19:06 UTC+0000 ...     1\n",
       "3070   2015-12-16 23:48:37 UTC+0000 ...     2\n",
       "1794   2015-03-09 11:20:00 UTC+0000 ...     3\n",
       "3045   2015-12-15 16:59:08 UTC+0000 ...     4\n",
       "1121   2014-05-15 16:57:38 UTC+0000 ...     5\n",
       "11580  2017-05-22 20:45:47 UTC+0000 ...     6\n",
       "23605  2018-09-25 23:10:33 UTC+0000 ...     7\n",
       "13045  2017-09-18 22:44:13 UTC+0000 ...     8\n",
       "15436  2018-01-17 20:18:04 UTC+0000 ...     9\n",
       "8782   2016-12-06 11:49:51 UTC+0000 ...    10\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_question_title=\"Is it hard to find a job in graphic design?\"\n",
    "input_question_body=\"I'd like to know how hard it is to find a job straight out of school  #graphic-design #graphics\"\n",
    "\n",
    "input_question=input_question_title+' '+input_question_body\n",
    "%time select_authors = select_author(input_question, **params)\n",
    "select_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method is a method of specifying the index of Framedata of \"questions\" by integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  \r\n",
      "CPU times: user 6.08 s, sys: 24 ms, total: 6.1 s\n",
      "Wall time: 6.07 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_date_joined</th>\n",
       "      <th>professionals_headline</th>\n",
       "      <th>professionals_id</th>\n",
       "      <th>professionals_industry</th>\n",
       "      <th>professionals_location</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22677</th>\n",
       "      <td>2018-09-01 20:47:44 UTC+0000</td>\n",
       "      <td>Adjunct Professor Engineering</td>\n",
       "      <td>e2b4c84bf1ca4aea9b108869692d8017</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>Greater Chicago Area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27147</th>\n",
       "      <td>2019-01-12 18:57:07 UTC+0000</td>\n",
       "      <td>Senior Product Line Manager, Servers &amp; Systems...</td>\n",
       "      <td>6cd927ff0179440f955400924564ea78</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3698</th>\n",
       "      <td>2016-01-27 14:51:09 UTC+0000</td>\n",
       "      <td>Retired Engineering Manager with limited consu...</td>\n",
       "      <td>81a594b683d54e6dbb4b04ea00a5e25b</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>Greensboro, Georgia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>2016-01-22 19:47:04 UTC+0000</td>\n",
       "      <td>Retired Civil Engineer</td>\n",
       "      <td>c3b4e11154f74a858779be7ba9b6f00c</td>\n",
       "      <td>Consulting Engineering</td>\n",
       "      <td>Kent, Washington</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16061</th>\n",
       "      <td>2018-02-16 01:56:13 UTC+0000</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>899f9fcf22d04191a294da40f7cc0ade</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>Newark, New Jersey</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25354</th>\n",
       "      <td>2018-11-15 03:24:17 UTC+0000</td>\n",
       "      <td>Product Marketing Dell</td>\n",
       "      <td>632f3cc0483642ceb798efef2b284cb0</td>\n",
       "      <td>Electrical and Electronic Manufacturing</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>2015-10-19 20:56:49 UTC+0000</td>\n",
       "      <td>Assist with Recognizing and Developing Potential</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>Mental Health Care</td>\n",
       "      <td>Cleveland, Ohio</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27427</th>\n",
       "      <td>2019-01-22 13:33:56 UTC+0000</td>\n",
       "      <td>PMO Business Manager at AT&amp;T</td>\n",
       "      <td>cb9c91e59ab9436d91b43c14e53be4c7</td>\n",
       "      <td>IT/Advertising, Analytics</td>\n",
       "      <td>Dallas/Fort Worth Area</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>2016-03-14 16:27:13 UTC+0000</td>\n",
       "      <td>Mechanical Engineer I Automotive</td>\n",
       "      <td>58fa5e95fe9e480a9349bbb1d7faaddb</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Redford Charter Township, Michigan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2014-02-21 20:16:29 UTC+0000</td>\n",
       "      <td>Software engineer, data infrastructure at Link...</td>\n",
       "      <td>19c30dfeabb64b108617c81d87f538fe</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sunnyvale, California</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          professionals_date_joined ...  rank\n",
       "22677  2018-09-01 20:47:44 UTC+0000 ...     1\n",
       "27147  2019-01-12 18:57:07 UTC+0000 ...     2\n",
       "3698   2016-01-27 14:51:09 UTC+0000 ...     3\n",
       "3611   2016-01-22 19:47:04 UTC+0000 ...     4\n",
       "16061  2018-02-16 01:56:13 UTC+0000 ...     5\n",
       "25354  2018-11-15 03:24:17 UTC+0000 ...     6\n",
       "2410   2015-10-19 20:56:49 UTC+0000 ...     7\n",
       "27427  2019-01-22 13:33:56 UTC+0000 ...     8\n",
       "4588   2016-03-14 16:27:13 UTC+0000 ...     9\n",
       "864    2014-02-21 20:16:29 UTC+0000 ...    10\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_question=123\n",
    "%time select_authors = select_author(input_question, **params)\n",
    "select_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of 'rand_coef' = 0.0005.\n",
    "    It can be used against cold start issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished  \r\n",
      "CPU times: user 6.2 s, sys: 40 ms, total: 6.24 s\n",
      "Wall time: 6.21 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>professionals_date_joined</th>\n",
       "      <th>professionals_headline</th>\n",
       "      <th>professionals_id</th>\n",
       "      <th>professionals_industry</th>\n",
       "      <th>professionals_location</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16061</th>\n",
       "      <td>2018-02-16 01:56:13 UTC+0000</td>\n",
       "      <td>Product Manager</td>\n",
       "      <td>899f9fcf22d04191a294da40f7cc0ade</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>Newark, New Jersey</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>2016-03-14 16:27:13 UTC+0000</td>\n",
       "      <td>Mechanical Engineer I Automotive</td>\n",
       "      <td>58fa5e95fe9e480a9349bbb1d7faaddb</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Redford Charter Township, Michigan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25354</th>\n",
       "      <td>2018-11-15 03:24:17 UTC+0000</td>\n",
       "      <td>Product Marketing Dell</td>\n",
       "      <td>632f3cc0483642ceb798efef2b284cb0</td>\n",
       "      <td>Electrical and Electronic Manufacturing</td>\n",
       "      <td>Austin, Texas</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>2016-01-22 19:47:04 UTC+0000</td>\n",
       "      <td>Retired Civil Engineer</td>\n",
       "      <td>c3b4e11154f74a858779be7ba9b6f00c</td>\n",
       "      <td>Consulting Engineering</td>\n",
       "      <td>Kent, Washington</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8739</th>\n",
       "      <td>2016-11-18 15:16:57 UTC+0000</td>\n",
       "      <td>EMEA Online Product Manager at Dell</td>\n",
       "      <td>d4b01aa328844ed882f25be3f3e45276</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22210</th>\n",
       "      <td>2018-08-27 20:15:47 UTC+0000</td>\n",
       "      <td>Cybersecurity Consultor Senior at PwC. Master ...</td>\n",
       "      <td>ae113c84e6e1469e9034ec6a7e0520b4</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>Mexico City, Mexico</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22677</th>\n",
       "      <td>2018-09-01 20:47:44 UTC+0000</td>\n",
       "      <td>Adjunct Professor Engineering</td>\n",
       "      <td>e2b4c84bf1ca4aea9b108869692d8017</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>Greater Chicago Area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>2015-10-05 16:46:15 UTC+0000</td>\n",
       "      <td>Senior Manager, Analytics Engineering and BI -...</td>\n",
       "      <td>f16a4f6374fd4e63a1f5ed24baa8eb5e</td>\n",
       "      <td>Information Technology and Services</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>2014-02-21 20:16:29 UTC+0000</td>\n",
       "      <td>Software engineer, data infrastructure at Link...</td>\n",
       "      <td>19c30dfeabb64b108617c81d87f538fe</td>\n",
       "      <td>Computer Software</td>\n",
       "      <td>Sunnyvale, California</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16179</th>\n",
       "      <td>2018-02-19 20:14:08 UTC+0000</td>\n",
       "      <td>Scrum Master @ AT&amp;T</td>\n",
       "      <td>ce9d21f7eefc42ec88f27e2cac7ff833</td>\n",
       "      <td>Telecommunications</td>\n",
       "      <td>St. Louis, Missouri</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          professionals_date_joined ...  rank\n",
       "16061  2018-02-16 01:56:13 UTC+0000 ...     5\n",
       "4588   2016-03-14 16:27:13 UTC+0000 ...     9\n",
       "25354  2018-11-15 03:24:17 UTC+0000 ...     6\n",
       "3611   2016-01-22 19:47:04 UTC+0000 ...     4\n",
       "8739   2016-11-18 15:16:57 UTC+0000 ...    40\n",
       "22210  2018-08-27 20:15:47 UTC+0000 ...    23\n",
       "22677  2018-09-01 20:47:44 UTC+0000 ...     1\n",
       "2312   2015-10-05 16:46:15 UTC+0000 ...    15\n",
       "864    2014-02-21 20:16:29 UTC+0000 ...    10\n",
       "16179  2018-02-19 20:14:08 UTC+0000 ...    11\n",
       "\n",
       "[10 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['rand_coef']=0.0005\n",
    "input_question=123\n",
    "%time select_authors = select_author(input_question, **params)\n",
    "select_authors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
